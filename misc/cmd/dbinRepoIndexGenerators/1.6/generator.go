// TODO: Add blessed selection, a cherry-picked repo made up of programs from autogenerated repos like pkgforge-go/pkgforge-cargo, this one would be included in the default repo index _AND_ as standalone
//   - We'll have a PickFrom() function that accepts a repository index (DbinMetadata) and a .Pkg and .PkgId, it uses these two to get us the item we want. We'll use this in our blessed repo.
package main

import (
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"sort"
	"strconv"
	"strings"

	"github.com/fxamacker/cbor/v2"
	"github.com/goccy/go-json"
	"github.com/klauspost/compress/zstd"
	minify "github.com/tdewolff/minify/v2"
	mjson "github.com/tdewolff/minify/v2/json"
	"github.com/tiendc/go-deepcopy"
)

const (
	colorRed    = "\033[31m"
	colorYellow = "\033[33m"
	colorReset  = "\033[0m"
)

type repository struct {
	URLs       []string
	Name       string
	Standalone bool
	Single     bool
	Filter     func(*[]DbinItem)
}

type PkgForgeItem struct {
	Pkg         string   `json:"pkg"`
	Name        string   `json:"pkg_name,omitempty"`
	Family      string   `json:"pkg_family,omitempty"`
	PkgId       string   `json:"pkg_id,omitempty"`
	AppId       string   `json:"app_id,omitempty"`
	PkgType     string   `json:"pkg_type,omitempty"`
	Icon        string   `json:"icon,omitempty"`
	Description string   `json:"description,omitempty"`
	Maintainers []string `json:"Maintainer,omitempty"`
	Screenshots []string `json:"screenshots,omitempty"`
	WebURLs     []string `json:"homepage,omitempty"`
	Version     string   `json:"version,omitempty"`
	DownloadURL string   `json:"download_url,omitempty"`
	Size        string   `json:"size,omitempty"`
	Bsum        string   `json:"bsum,omitempty"`
	Shasum      string   `json:"shasum,omitempty"`
	BuildDate   string   `json:"build_date,omitempty"`
	SrcURLs     []string `json:"src_url,omitempty"`
	BuildScript string   `json:"build_script,omitempty"`
	BuildLog    string   `json:"build_log,omitempty"`
	Category    []string `json:"categories,omitempty"`
	Snapshots   []string `json:"snapshots,omitempty"`
	Provides    []string `json:"provides,omitempty"`
	Notes       []string `json:"note,omitempty"`
	License     []string `json:"license,omitempty"`
	GhcrPkg     string   `json:"ghcr_pkg,omitempty"`
	HfPkg       string   `json:"hf_pkg,omitempty"`
	Rank        string   `json:"rank,omitempty"`
	WebManifest string   `json:"pkg_webpage,omitempty"`
}

type snapshot struct {
	Commit  string `json:"commit,omitempty"`
	Version string `json:"version,omitempty"`
}

type DbinItem struct {
	Pkg             string     `json:"pkg,omitempty"`
	Name            string     `json:"pkg_name,omitempty"`
	PkgId           string     `json:"pkg_id,omitempty"`
	AppstreamId     string     `json:"app_id,omitempty"`
	Icon            string     `json:"icon,omitempty"`
	Description     string     `json:"description,omitempty"`
	LongDescription string     `json:"description_long,omitempty"`
	Screenshots     []string   `json:"screenshots,omitempty"`
	Version         string     `json:"version,omitempty"`
	DownloadURL     string     `json:"download_url,omitempty"`
	Size            string     `json:"size,omitempty"`
	Bsum            string     `json:"bsum,omitempty"`
	Shasum          string     `json:"shasum,omitempty"`
	BuildDate       string     `json:"build_date,omitempty"`
	SrcURLs         []string   `json:"src_urls,omitempty"`
	WebURLs         []string   `json:"web_urls,omitempty"`
	BuildScript     string     `json:"build_script,omitempty"`
	BuildLog        string     `json:"build_log,omitempty"`
	Categories      string     `json:"categories,omitempty"`
	Snapshots       []snapshot `json:"snapshots,omitempty"`
	Provides        string     `json:"provides,omitempty"`
	License         []string   `json:"license,omitempty"`
	Maintainers     string     `json:"maintainers,omitempty"`
	Notes           []string   `json:"notes,omitempty"`
	Appstream       string     `json:"appstream,omitempty"`
	Rank            uint       `json:"rank,omitempty"`
	WebManifest     string     `json:"web_manifest,omitempty"`
}

type DbinMetadata map[string][]DbinItem

type RepositoryHandler interface {
	FetchMetadata(urls []string, arch string) ([]DbinItem, error)
}

type PkgForgeHandler struct{}

func (PkgForgeHandler) FetchMetadata(urls []string, arch string) ([]DbinItem, error) {
	return fetchAndConvertMetadata(urls, arch, downloadJSON, convertPkgForgeToDbinItem)
}

type DbinHandler struct{}

func (DbinHandler) FetchMetadata(urls []string, arch string) ([]DbinItem, error) {
	var lastErr error

	for i, urlTemplate := range urls {
		url := urlTemplate
		if strings.Contains(url, "%s") {
			url = fmt.Sprintf(url, arch)
		}

		if i > 0 {
			fmt.Printf("Using fallback URL: %s\n", url)
		}

		resp, err := http.Get(url)
		if err != nil {
			lastErr = err
			continue
		}
		defer resp.Body.Close()

		body, err := io.ReadAll(resp.Body)
		if err != nil {
			lastErr = err
			continue
		}

		var metadata DbinMetadata
		err = json.Unmarshal(body, &metadata)
		if err != nil {
			lastErr = err
			continue
		}

		// Since the metadata is already in Dbin format, we just need to extract the items
		for _, items := range metadata {
			return items, nil
		}
	}

	return nil, lastErr
}

type AppStreamMetadata struct {
	AppId           string   `json:"app_id"`
	Categories      string   `json:"categories"`
	RichDescription string   `json:"rich_description"`
	Icons           []string `json:"icons"`
	Screenshots     []string `json:"screenshots"`
}

var appStreamMetadata []AppStreamMetadata
var appStreamMetadataLoaded bool

func loadAppStreamMetadata() error {
	if appStreamMetadataLoaded {
		return nil
	}

	//resp, err := http.Get("https://d.xplshn.com.ar/misc/cmd/flatpakAppStreamScrapper/appstream_metadata.cbor")
	resp, err := http.Get("https://github.com/xplshn/dbin-metadata/raw/refs/heads/master/misc/cmd/flatpakAppStreamScrapper/appstream_metadata.cbor.zst")
	if err != nil {
		return fmt.Errorf("failed to fetch Flathub AppStream metadata: %v", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return fmt.Errorf("failed to read response body: %v", err)
	}

	zstdReader, err := zstd.NewReader(nil, zstd.WithDecoderConcurrency(1))
	if err != nil {
		return fmt.Errorf("failed to create zstd reader: %v", err)
	}
	defer zstdReader.Close()

	decompressed, err := zstdReader.DecodeAll(body, nil)
	if err != nil {
		return fmt.Errorf("failed to decompress data: %v", err)
	}

	err = cbor.Unmarshal(decompressed, &appStreamMetadata)
	if err != nil {
		return fmt.Errorf("failed to unmarshal Flathub AppStream metadata: %v", err)
	}

	appStreamMetadataLoaded = true
	return nil
}

func updateItemWithAppStreamMetadata(item *DbinItem) {
	if item.AppstreamId == "" {
		return
	}

	for _, metadata := range appStreamMetadata {
		if metadata.AppId == item.AppstreamId {
			if len(metadata.Icons) > 0 {
				item.Icon = metadata.Icons[0]
			}
			if len(metadata.Screenshots) > 0 {
				item.Screenshots = metadata.Screenshots
			}
			if metadata.Categories != "" {
				item.Categories = metadata.Categories
			}
			if metadata.RichDescription != "" {
				item.LongDescription = metadata.RichDescription
			}
			break
		}
	}
}

func fetchAndConvertMetadata(urls []string, arch string, downloadFunc func([]string, string) ([]PkgForgeItem, error), convertFunc func(PkgForgeItem, map[string]bool) (DbinItem, bool)) ([]DbinItem, error) {
	items, err := downloadFunc(urls, arch)
	if err != nil {
		return nil, err
	}

	familyCount := make(map[string]int)
	familyNames := make(map[string]string)
	useFamilyFormat := make(map[string]bool)

	for _, item := range items {
		familyCount[item.Family]++
		if familyNames[item.Family] == "" {
			familyNames[item.Family] = item.Name
		} else if familyNames[item.Family] != item.Name {
			useFamilyFormat[item.Family] = true
		}
	}

	var dbinItems []DbinItem
	for _, item := range items {
		dbinItem, include := convertFunc(item, useFamilyFormat)
		if include {
			updateItemWithAppStreamMetadata(&dbinItem)
			dbinItems = append(dbinItems, dbinItem)
		}
	}

	return dbinItems, nil
}

func convertPkgForgeToDbinItem(item PkgForgeItem, useFamilyFormat map[string]bool) (DbinItem, bool) {
	// PkgTypes we discard, completely
	if item.PkgType == "dynamic" {
		return DbinItem{}, false
	}

	var categories, provides, maintainers, downloadURL string

	if len(item.Category) > 0 {
		categories = strings.Join(item.Category, ",")
	}

	if len(item.Provides) > 0 {
		provides = strings.Join(item.Provides, ",")
	}

	if len(item.Maintainers) > 0 {
		maintainers = strings.Join(item.Maintainers, ",")
	}

	if item.GhcrPkg != "" {
		downloadURL = "oci://" + item.GhcrPkg
	} else if item.HfPkg != "" {
		downloadURL = strings.Replace(item.HfPkg, "/tree/main", "/resolve/main", 1) + "/" + item.Pkg
	} else if item.DownloadURL != "" {
		downloadURL = item.DownloadURL
	}

	rank, _ := strconv.Atoi(item.Rank)

	// Parse snapshots
	var snapshots []snapshot
	for _, snapshotStr := range item.Snapshots {
		parts := strings.Split(snapshotStr, "[")
		commit := strings.TrimSpace(parts[0])
		version := ""
		if len(parts) > 1 {
			version = strings.TrimSuffix(parts[1], "]")
		}
		snapshots = append(snapshots, snapshot{Commit: commit, Version: version})
	}

	// Would love to do this: but Snapshots doesn't update as often as it should for this to be feasible
	//if strings.HasPrefix(item.Version, "HEAD-") && len(snapshots) >= 1 {
	//	if snapshots[0].Version != "" {
	//		item.Version = snapshots[0].Version
	//	}
	//}

	// - Determine the package name format
	//   | - If all packages in a family have the same name (e.g., "bwrap" in the "bubblewrap" family),
	//   |   the package name will be just the package name (e.g., "bwrap").
	//   | - If there are multiple packages with different names in a family, the format will be
	//   |   "family/package_name" (e.g., "a-utils/ccat").
	// - Applies to all occurrences
	pkgName := item.Name
	if item.Family != "" && useFamilyFormat[item.Family] {
		pkgName = fmt.Sprintf("%s/%s", item.Family, item.Name)
	}

	if item.PkgType == "static" {
		pkgName = strings.TrimSuffix(pkgName, ".static")
	} else if item.PkgType == "archive" {
		pkgName = strings.TrimSuffix(pkgName, ".archive")
	} else if item.PkgType != "" {
		pkgName = pkgName + "." + item.PkgType
	}

	item.Pkg = strings.TrimPrefix(item.Pkg, "/")

	if areSlicesEqual(item.SrcURLs, item.WebURLs) {
		item.WebURLs = []string{}
	}

	return DbinItem{
		Pkg:         pkgName,
		Name:        item.Name,
		PkgId:       item.PkgId,
		AppstreamId: item.AppId,
		Icon:        item.Icon,
		Screenshots: item.Screenshots,
		Description: item.Description,
		Version:     item.Version,
		DownloadURL: downloadURL,
		Size:        item.Size,
		Bsum:        item.Bsum,
		Shasum:      item.Shasum,
		BuildDate:   item.BuildDate,
		SrcURLs:     item.SrcURLs,
		WebURLs:     item.WebURLs,
		BuildScript: item.BuildScript,
		BuildLog:    item.BuildLog,
		Categories:  categories,
		Snapshots:   snapshots,
		Provides:    provides,
		License:     item.License,
		Maintainers: maintainers,
		Notes:       item.Notes,
		Rank:        uint(rank),
		WebManifest: item.WebManifest,
	}, true
}

func downloadJSON(urls []string, arch string) ([]PkgForgeItem, error) {
	var lastErr error

	for i, urlTemplate := range urls {
		url := urlTemplate
		if strings.Contains(url, "%s") {
			url = fmt.Sprintf(url, arch)
		}

		if i > 0 {
			fmt.Printf("Using fallback URL: %s\n", url)
		}

		resp, err := http.Get(url)
		if err != nil {
			lastErr = err
			continue
		}
		defer resp.Body.Close()

		body, err := io.ReadAll(resp.Body)
		if err != nil {
			lastErr = err
			continue
		}

		var items []PkgForgeItem
		err = json.Unmarshal(body, &items)
		if err != nil {
			lastErr = err
			continue
		}

		return items, nil
	}

	return nil, lastErr
}

func reorderItems(str []map[string]string, metadata DbinMetadata) {
	for _, replacements := range str {
		for repo, items := range metadata {
			// Replace str with str2
			for oldStr, newStr := range replacements {
				for i := range items {
					items[i].PkgId = strings.ReplaceAll(items[i].PkgId, oldStr, newStr)
				}
			}

			// Sort items alphabetically by BinId
			sort.Slice(items, func(i, j int) bool {
				return items[i].PkgId < items[j].PkgId
			})

			// Replace str2 back to str
			for oldStr, newStr := range replacements {
				for i := range items {
					items[i].PkgId = strings.ReplaceAll(items[i].PkgId, newStr, oldStr)
				}
			}

			metadata[repo] = items
		}
	}
}

func saveAll(filename string, metadata DbinMetadata) error {
	if err := saveJSON(filename, metadata); err != nil {
		return err
	}
	return saveCBOR(filename, metadata)
}

func saveMetadata(filename string, metadata DbinMetadata) error {
	// Reorder items alphabetically but with priority exceptions, to ensure a higher level of quality.
	// We basically do a search&replace, order alphabetically, and then do a search&replace again.
	// I prioritize binaries with a smaller size, more hardware compat, and that are truly static.
	reorderItems([]map[string]string{
		{"musl": "0000_"},    // | Higher priority for Musl
		{"ppkg": "0020__"},   // | Higher priority for ppkg
		{"glibc": "0040___"}, // | Push glibc to the end
		// -					 // | - Little Glenda says hi!
		// -      				 // |   (\(\
		{"musl-v3": "0080_"},    // |   ¸". ..
		{"glibc-v3": "0100___"}, // |   (  . .)
		// -    				 // |   |   ° ¡
		{"musl-v4": "0200_"},    // |   ¿     ;
		{"glibc-v4": "0400___"}, // |  c?".UJ"
	}, metadata)

	if err := saveAll(filename, metadata); err != nil {
		return err
	}

	// "web" version
	var webMetadata DbinMetadata
	_ = deepcopy.Copy(&webMetadata, &metadata)
	for _, items := range webMetadata {
		for i := range items {
			items[i].Provides = ""
			items[i].Shasum = ""
			items[i].Bsum = ""
			items[i].WebManifest = ""
		}
	}
	saveAll(filename+".web", webMetadata)
	// "nlite" version
	for _, items := range metadata {
		for i := range items {
			items[i].Icon = ""
			items[i].Provides = ""
			items[i].Shasum = ""
			items[i].AppstreamId = ""
			items[i].LongDescription = ""
			items[i].Screenshots = []string{}
		}
	}
	saveAll(filename+".nlite", metadata)
	// "lite" version
	for _, items := range metadata {
		for i := range items {
			items[i].Icon = ""
			items[i].Provides = ""
			items[i].Shasum = ""
			items[i].AppstreamId = ""
			items[i].LongDescription = ""
			items[i].WebManifest = ""
			items[i].Screenshots = []string{}
		}
	}
	return saveAll(filename+".lite", metadata)
}

func saveCBOR(filename string, metadata DbinMetadata) error {
	cborData, err := cbor.Marshal(metadata)
	if err != nil {
		return err
	}
	return os.WriteFile(filename+".cbor", cborData, 0644)
}
func saveJSON(filename string, metadata DbinMetadata) error {
	jsonData, err := json.MarshalIndent(metadata, "", " ")
	if err != nil {
		return err
	}
	if err := os.WriteFile(filename+".json", jsonData, 0644); err != nil {
		return err
	}
	// Minify JSON
	m := minify.New()
	m.AddFunc("application/json", mjson.Minify)
	if jsonData, err = m.Bytes("application/json", jsonData); err != nil {
		return err
	} else if err := os.WriteFile(filename+".min.json", jsonData, 0644); err != nil {
		return err
	}
	return nil
}

func main() {
	// Load AppStream metadata once at startup
	if err := loadAppStreamMetadata(); err != nil {
		fmt.Printf("%serror:%s Error loading AppStream metadata: %v\n", colorRed, colorReset, err)
	}

	realArchs := map[string]string{
		"x86_64-Linux":  "amd64_linux",
		"aarch64-Linux": "arm64_linux",
		"riscv64-Linux": "riscv64_linux",
		"loong64-Linux": "loongarch64_linux",
	}

	// At least the amd64 repo should have succeeded in order for the fetch failure
	// of a repo for a specifc arch to be considered a warning instead of an error.
	amd64Success := false

	repositories := []struct {
		Repo    repository
		Handler RepositoryHandler
	}{
		{
			Repo: repository{
				Name: "bincache",
				URLs: []string{
					"https://github.com/pkgforge/metadata/raw/refs/heads/main/bincache/data/%s.json",
					"https://meta.pkgforge.dev/bincache/%s.json",
				},
				Single: true,
			},
			Handler: PkgForgeHandler{},
		},
		{
			Repo: repository{
				Name: "pkgcache",
				URLs: []string{
					"https://github.com/pkgforge/metadata/raw/refs/heads/main/pkgcache/data/%s.json",
					"https://meta.pkgforge.dev/pkgcache/%s.json",
				},
				Single: true,
				Filter: func(items *[]DbinItem) {
					var filteredItems []DbinItem
					for _, item := range *items {
						hasPortableNote := false
						for _, note := range item.Notes {
							if strings.Contains(note, "[PORTABLE]") {
								hasPortableNote = true
								break
							}
						}
						if hasPortableNote {
							filteredItems = append(filteredItems, item)
						}
					}
					*items = filteredItems
				},
			},
			Handler: PkgForgeHandler{},
		},
		{
			Repo: repository{
				Name: "pkgforge-go",
				URLs: []string{
					"https://github.com/pkgforge-go/builder/raw/refs/heads/main/data/%s.json",
					"https://meta.pkgforge.dev/external/pkgforge-go/%s.json",
				},
				Standalone: true,
				Filter: func(items *[]DbinItem) {
					var filteredItems []DbinItem
					for _, item := range *items {
						//if !strings.Contains(item.Description, "bindings") && !strings.Contains(item.Description, "key") {
						//	filteredItems = append(filteredItems, item)
						//} /* else {
						//	fmt.Printf("[pkgforge-go]: repo filter: %s#%s contains bad word (%s)", item.Name, item.PkgId, "bindings")
						//} */
						item.PkgId = strings.Replace(item.PkgId, "#", ".", -1)
						filteredItems = append(filteredItems, item)
					}
					*items = filteredItems
				},
			},
			Handler: PkgForgeHandler{},
		},
		{
			Repo: repository{
				Name: "pkgforge-cargo",
				URLs: []string{
					"https://raw.githubusercontent.com/pkgforge-cargo/builder/refs/heads/main/data/x86_64-Linux.json",
					"https://meta.pkgforge.dev/external/pkgforge-cargo/%s.json",
					"https://github.com/pkgforge-cargo/builder/raw/refs/heads/main/data/%s.json",
				},
				Standalone: true,
			},
			Handler: PkgForgeHandler{},
		},
		{
			Repo: repository{
				Name: "AM",
				URLs: []string{
					"https://github.com/pkgforge/metadata/raw/refs/heads/main/external/am/data/%s.json",
					"https://meta.pkgforge.dev/external/am/%s.json",
				},
				Standalone: true,
			},
			Handler: PkgForgeHandler{},
		},
		{
			Repo: repository{
				Name: "appimage-github-io",
				URLs: []string{
					"https://github.com/pkgforge/metadata/raw/refs/heads/main/external/appimage.github.io/data/%s.json",
					"https://meta.pkgforge.dev/external/appimage.github.io/%s.json",
				},
				Standalone: true,
			},
			Handler: PkgForgeHandler{},
		},
		{
			Repo: repository{
				Name: "AppBundleHUB",
				URLs: []string{
					"https://github.com/xplshn/AppBundleHUB/releases/download/latest_metadata/metadata_%s.json",
				},
				Single: true,
			},
			Handler: DbinHandler{},
		},
	}

	for arch, outputArch := range realArchs {
		dbinMetadata := make(DbinMetadata)
		archSuccess := false // Track success for the current architecture

		for _, repo := range repositories {
			items, err := repo.Handler.FetchMetadata(repo.Repo.URLs, arch)
			if err != nil {
				// If amd64 succeeded, treat non-amd64 failures as warnings
				if arch != "x86_64-Linux" && amd64Success {
					fmt.Printf("%swarning:%s Failed to download %s metadata for %s: %v\n", colorYellow, colorReset, repo.Repo.Name, arch, err)
					continue
				} else {
					fmt.Printf("%serror:%s Error downloading %s metadata for %s: %v\n", colorRed, colorReset, repo.Repo.Name, arch, err)
					continue
				}
			}

			if repo.Repo.Filter != nil {
				repo.Repo.Filter(&items)
			}

			if !repo.Repo.Standalone {
				dbinMetadata[repo.Repo.Name] = append(dbinMetadata[repo.Repo.Name], items...)
			}

			if repo.Repo.Single || repo.Repo.Standalone {
				singleMetadata := make(DbinMetadata)
				singleMetadata[repo.Repo.Name] = items
				singleOutputFile := fmt.Sprintf("%s_%s", repo.Repo.Name, outputArch)

				if err := saveMetadata(singleOutputFile, singleMetadata); err != nil {
					fmt.Printf("%serror:%s Error saving single metadata to %s: %v\n", colorRed, colorReset, singleOutputFile, err)
					continue
				}
				fmt.Printf("Successfully saved single metadata to %s\n", singleOutputFile)
			}

			archSuccess = true // Mark this architecture as successful if at least one repo processed
		}

		// Update amd64Success if this is the amd64 architecture
		if arch == "x86_64-Linux" && archSuccess {
			amd64Success = true
		}

		// Save combined metadata only if the architecture had at least one successful repo
		if archSuccess {
			outputFile := fmt.Sprintf("%s", outputArch)
			if err := saveMetadata(outputFile, dbinMetadata); err != nil {
				fmt.Printf("%serror:%s Error saving metadata to %s: %v\n", colorRed, colorReset, outputFile, err)
				continue
			}
			fmt.Printf("Successfully processed and saved combined metadata to %s\n", outputFile)
		} else if arch != "x86_64-Linux" && amd64Success {
			fmt.Printf("%swarning:%s No metadata saved for %s: all repositories failed\n", colorYellow, colorReset, outputArch)
		} else {
			fmt.Printf("%serror:%s No metadata saved for %s: all repositories failed\n", colorRed, colorReset, outputArch)
		}
	}
}

func areSlicesEqual(a, b []string) bool {
	if len(a) != len(b) {
		return false
	}
	for i, v := range a {
		if v != b[i] {
			return false
		}
	}
	return true
}

func t[T any](cond bool, vtrue, vfalse T) T {
	if cond {
		return vtrue
	}
	return vfalse
}

/* AM is one of the most relevant projects of the portable Linux apps community
 * And the AM repo is a thirdparty optional repo in `dbin`, so its only fair that
 * we help them distribute more programs too!                                   -
 */
const pipeRepl = "ǀ" // Replacement for `|` to avoid breaking the MD table
func replacePipeFields(pkg *DbinItem) {
	pkg.Name = strings.ReplaceAll(pkg.Name, "|", pipeRepl)
	pkg.Description = strings.ReplaceAll(pkg.Description, "|", pipeRepl)
	pkg.DownloadURL = strings.ReplaceAll(pkg.DownloadURL, "|", pipeRepl)
	for i := range pkg.WebURLs {
		pkg.WebURLs[i] = strings.ReplaceAll(pkg.WebURLs[i], "|", pipeRepl)
	}
}
func genAMMeta(filename string, metadata DbinMetadata) {
	file, err := os.Create(filename + ".txt")
	if err != nil {
		fmt.Println("Error creating output file:", err)
		return
	}
	defer file.Close()

	file.WriteString("| appname | description | site | download | version |\n")
	file.WriteString("|---------|-------------|------|----------|---------|\n")

	var allEntries []DbinItem
	for _, entries := range metadata {
		allEntries = append(allEntries, entries...)
	}

	sort.Slice(allEntries, func(i, j int) bool {
		return strings.ToLower(allEntries[i].Name) < strings.ToLower(allEntries[j].Pkg)
	})

	for _, entry := range allEntries {
		pkg := strings.TrimSuffix(entry.Pkg, filepath.Ext(entry.Pkg))

		if pkg != "" {
			entry.Pkg = pkg
		}

		siteURL := ""
		if len(entry.SrcURLs) > 0 {
			siteURL = entry.SrcURLs[0]
		} else if len(entry.WebURLs) > 0 {
			siteURL = entry.WebURLs[0]
		} else {
			siteURL = "https://github.com/xplshn/dbin"
		}

		version := entry.Version
		if version == "" && entry.BuildDate != "" {
			version = entry.BuildDate
		}
		if version == "" {
			version = "not_available"
		}

		file.WriteString(fmt.Sprintf("| %s | %s | %s | %s | %s |\n",
			pkg,
			t(entry.Description != "", entry.Description, "not_available"),
			t(siteURL != "", siteURL, "not_available"),
			entry.DownloadURL,
			t(version != "", version, "not_available"),
		))
	}
}
